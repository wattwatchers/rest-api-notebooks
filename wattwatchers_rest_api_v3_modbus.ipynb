{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ_ZSE_bDOHS"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wattwatchers/rest-api-notebooks/blob/main/wattwatchers_rest_api_v3_modbus.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YcHL4FNiaFu"
   },
   "source": [
    "# Introduction\n",
    "This is a Jupyter notebook to quickly get you started with (some of) the API endpoints of the Wattwatchers REST API v3 (Mercury).\n",
    "This notebook is specifically focused on downloading modbus data. This notebook is developed to be used on Google Colab.\n",
    "\n",
    "The official documentation for the API can be found [here](https://docs.wattwatchers.com.au/api/v3/index.html).\n",
    "\n",
    "There are two ways to use this notebook:\n",
    "\n",
    "1. If you just want to download modbus data for all devices associated with your API key (and not write any code yourself), just enter the details of your request in the Configuration section and run the whole book (`Runtime/Run all`)\n",
    "2. As a starting point to learn about the API and make different requests. In that case you can adjust any code in this notebook to your needs and run it.\n",
    "\n",
    "To run the code in this notebook, hover your cursor over the brackets (`[ ]`) in the top left corner of a code block. Then click the play button. \n",
    "\n",
    "To run all code in the notebook select `Runtime/Run all` from the menu at the top of the page. This will download modbus data for all devices associated with your API key and save it to file based on the constants defined in the Configuration code block. As part of this process you need to follow the steps when prompted to mount your Google Drive (so the output file can be saved to your Google Drive account). NOTE: Depending on how many devices are associated with the API key and the time period requests, downloading the modbus data can take a long time.\n",
    "\n",
    "For details on how access your API key, see the [\"Authentication & Authroization\" section of our API docs](https://docs.wattwatchers.com.au/api/v3/auth.html). REMEMBER: Your API key is just like a passwordâ€”make sure you transfer and store it securely at all times (not via email etc.).\n",
    "\n",
    "Go [here](https://colab.research.google.com/github/coolernato/Introduction-to-Python/blob/master/Using%20Jupyter%20Notebooks.ipynb) to learn move about using Jupyter Notebooks on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llIheA0BUEs_"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Insert your API key in the code block below.\n",
    "Adjust any of the other constants to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vu2nX9k7jK9S"
   },
   "outputs": [],
   "source": [
    "# Insert your API key below (between the quotation marks)\n",
    "API_KEY = \"\" \n",
    "\n",
    "DEFAULT_TIMEZONE = \"Australia/Sydney\" # The timezone to use in cases where a device's timezone is not known\n",
    "START_DATE = \"2024-07-24T00:00:00\"    # Date string in the format <YYYY-MM-DD>T<HH:MM:SS> in the target timezone\n",
    "END_DATE = \"2024-07-28T00:00:00\"      # Date string in the format <YYYY-MM-DD>T<HH:MM:SS> in the target timezone\n",
    "\n",
    "FILE_NAME = \"exported-data\"           # desired name for the file containing the exported data (or the start of the filename if data is exported to multiple files). Do not include the file extension.\n",
    "INCLUDE_DATE_AND_TIME = True          # True or False. If set to True, date and time strings will be included in the exported data (in addition to Unix timestamps)\n",
    "OUTPUT_FORMAT = \"csv\"                 # either json or csv\n",
    "DOWNLOAD_FILE = True                  # True or False. If set to True the file containing the exported data will be downloaded to your local machine after it has been saved to Google Drive.\n",
    "ONE_FILE_PER_DEVICE = False           # True or False. Applicable to CSV exports only. \n",
    "                                      # If True, saves data for each device to its own CSV file; the file name will include the device id. \n",
    "                                      # If False, saves all device data to a single CSV file and outputs a second file allowing individual device channels to be mapped to their categories\n",
    "\n",
    "BASE_URL = \"https://api-v3.wattwatchers.com.au\" # Do not modify this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_cK6QhNqez1"
   },
   "source": [
    "# Mounting Google Drive\n",
    "In order to save the dowloaded data in a file, you need to connect this notebook to your Google Drive account by running the code block below and following the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGVV9UEIqcNb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iSqVI5xkOR6"
   },
   "source": [
    "## Request batching and throttling\n",
    "\n",
    "Because the API has limits on the amount of data it returns for a single request, and on the number of calls it accepts in a time period, we need some methods to split large requests into batches and to throttle the requests we make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWDuC-K0k4oa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def throttler(last_request_time: float, max_requests_per_sec: int = 2):\n",
    "  \"\"\"\n",
    "  The API is rate limited and therefore API requests may need to be throttled.\n",
    "  This method throttles API request based on when the last request was made and the number of requests per second we are allowed to make \n",
    "  (the actual frequency of requests can be lower than the maximum allowed if requests take longer to complete than the minimum interval \n",
    "  between requests)\n",
    "  \"\"\"\n",
    "  if last_request_time is None:\n",
    "    return\n",
    "  time_since_last_request = time.time() - last_request_time\n",
    "  wait_duration = max(0, 1/max_requests_per_sec - time_since_last_request)\n",
    "  if wait_duration > 0:\n",
    "    time.sleep(wait_duration)\n",
    "\n",
    "def calculate_batches_for(end_timestamp: int, time_interval: int) -> list:\n",
    "  \"\"\"\"\n",
    "  Because we can only request 7 days of data in a API call, we need to break up our time interval into batches. \n",
    "  This method returns the time intervals for each API call to cover the full desired time interval.\n",
    "  \"\"\"\n",
    "  batch_interval = 7 * 24 * 60 * 60\n",
    "  start_timestamp = end_timestamp - time_interval\n",
    "  intervals = [(batch_start, min(batch_start + batch_interval, end_timestamp)) for batch_start in range(start_timestamp, end_timestamp, batch_interval)]\n",
    "  return intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aehrt0BUI1RE"
   },
   "source": [
    "# Convenience methods to convert dates to timestamps\n",
    "\n",
    "The API methods above use timestamps and time intervals. \n",
    "Below is a convenience method to convert two date and time strings to Unix UTC timestamp and interval to pass into the API methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO0dXSWLASYh"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pytz \n",
    "\n",
    "def convert_dates_to_timestamp_and_interval(\n",
    "    start_date_str: str, \n",
    "    end_date_str: str, \n",
    "    timezone_str: str = DEFAULT_TIMEZONE, \n",
    "    date_format: str = \"%Y-%m-%dT%H:%M:%S\") -> tuple:\n",
    "  \"\"\"\n",
    "  Convenience method to convert a start date and end date string\n",
    "  into a end timestamp and interval that can be used as parameters for the API methods.\n",
    "  Start and end date parameters are to be formatted as \"2021-06-29 17:08:00\" (or according to the date_format parameter passed in)\n",
    "  Dates are set to the timezone string passed in (defaults to DEFAULT_TIMEZONE)\n",
    "  The method returns a tuple containing the end timestamp and the time interval.\n",
    "  \"\"\"\n",
    "  timezone = pytz.timezone(timezone_str)\n",
    "  start_timestamp = convert_date_to_timestamp(start_date_str, timezone, date_format)\n",
    "  end_timestamp = convert_date_to_timestamp(end_date_str, timezone, date_format)\n",
    "  return (end_timestamp, end_timestamp - start_timestamp)\n",
    "\n",
    "def convert_date_to_timestamp(date_str: str, timezone: pytz.timezone, date_format: str) -> int:\n",
    "  \"\"\"\n",
    "  Helper method to convert a date string for a given timezone to a timestamp\n",
    "  \"\"\"\n",
    "  date_time = timezone.localize(dt.datetime.strptime(date_str, date_format))\n",
    "  return int(date_time.timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "athsDe05VJS0"
   },
   "source": [
    "## API request methods\n",
    "\n",
    "Generic methods to make API requests.\n",
    "These methods are not specific to a particular endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH2ZbiacoRXb"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Basic GET request method\n",
    "def get_request(path: str, query_params: dict = {}, token: str = API_KEY):\n",
    "  endpoint = BASE_URL + path\n",
    "  headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "  return requests.get(endpoint, params=query_params, headers=headers)\n",
    "\n",
    "def load(endpoint: str, end_timestamp: int, time_interval: int) -> list:\n",
    "  \"\"\"\n",
    "  Method that turns a request for a long time period into a batch of API calls,\n",
    "  makes the (throttled) API calls, and concatenates the data returned from the calls. \n",
    "  \"\"\"\n",
    "  batches_intervals = calculate_batches_for(end_timestamp, time_interval)\n",
    "  all_data = []\n",
    "  last_request_time = None\n",
    "  target_requests_per_second = 2 # Conservative default, this will be updated with header values after the first request\n",
    "  for from_ts, to_ts in batches_intervals:\n",
    "    throttler(last_request_time, target_requests_per_second)\n",
    "    last_request_time = time.time()\n",
    "    query_params = {\"fromTs\": from_ts, \"toTs\": to_ts}\n",
    "    result = get_request(endpoint, query_params)\n",
    "    if result.status_code != 200:\n",
    "      print(\"failed to load batch. status code: \", result.status_code, result.content)\n",
    "      continue\n",
    "    target_requests_per_second = int(result.headers[\"X-RateLimit-TpsLimit\"])\n",
    "    data = result.json()\n",
    "    all_data += data\n",
    "  return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AN9n8Ob1Vcoc"
   },
   "source": [
    "## Methods for specific API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_j67fv7pWIf"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Optional\n",
    "\n",
    "def get_devices_list() -> Optional[list]:\n",
    "  \"\"\"\n",
    "  Method to load all device ids associated with the API key.\n",
    "  \"\"\"\n",
    "  result = get_request(\"/devices\")\n",
    "  if result.status_code != 200:\n",
    "    print(\"get_devices_list failed with status code\", result.status_code)\n",
    "    return None\n",
    "  return result.json()\n",
    "\n",
    "def get_device_status(device_id: str) -> Optional[dict]:\n",
    "  \"\"\"\n",
    "  Method to load metadata for a specific device.\n",
    "  \"\"\"\n",
    "  result = get_request(f\"/devices/{device_id}\")\n",
    "  if result.status_code != 200:\n",
    "    print(\"get_device_status failed:\", result.status_code)\n",
    "    return None\n",
    "  return result.json()\n",
    "\n",
    "def get_first_modbus_timestamp(device_id: str) -> Optional[dict]:\n",
    "  \"\"\"\n",
    "  Method to get the timestamp of the first available modbus data for a device\n",
    "  Used to limit the requested time interval for a device if the requested interval\n",
    "  starts before the first available data for the device\n",
    "  \"\"\"\n",
    "  query_params = {\"fields[energy]\": \"timestamp\"}\n",
    "  result = get_request(f\"/modbus/{device_id}/first\", query_params)\n",
    "  if result.status_code != 200:\n",
    "    print(\"get_first_timestamp failed:\", result.status_code)\n",
    "    return None\n",
    "  return result.json()\n",
    "\n",
    "def get_latest_modbus_timestamp(device_id: str) -> Optional[dict]:\n",
    "  \"\"\"\n",
    "  Method to get the timestamp of the latest available modbus data for a device\n",
    "  Used to limit the requested time interval for a device if the requested interval\n",
    "  ends after the latest available data for the device\n",
    "  \"\"\"\n",
    "  query_params = {\"fields[energy]\": \"timestamp\"}\n",
    "  result = get_request(f\"/modbus/{device_id}/latest\", query_params)\n",
    "  if result.status_code != 200:\n",
    "    print(\"get_latest_timestamp failed:\", result.status_code)\n",
    "    return None\n",
    "  return result.json()\n",
    "\n",
    "def adjusted_time_period_for(device_id: str, end_timestamp: int, time_interval: int) -> Optional[tuple[int, int]]:\n",
    "  \"\"\"\n",
    "  Method to adjust the requested time period based on the timestamps of the first and latest available modbus data.\n",
    "  Returns None if the requested time period does not intersect with available data.\n",
    "  Returns adjusted end_timestamp and time_interval values if the requested time period \n",
    "  partly intersects with the the available data.\n",
    "  \"\"\"\n",
    "  first_timestamp_result = get_first_modbus_timestamp(device_id)\n",
    "  latest_timestamp_result = get_latest_modbus_timestamp(device_id)\n",
    "  if first_timestamp_result is None or latest_timestamp_result is None:\n",
    "    return None\n",
    "  first_timestamp = first_timestamp_result[\"timestamp\"]\n",
    "  latest_timestamp = latest_timestamp_result[\"timestamp\"]\n",
    "  if first_timestamp > end_timestamp or latest_timestamp < end_timestamp - time_interval:\n",
    "    return None\n",
    "  if first_timestamp > end_timestamp - time_interval:\n",
    "    time_interval = end_timestamp - first_timestamp\n",
    "  if latest_timestamp < end_timestamp:\n",
    "    time_interval = time_interval - (end_timestamp - latest_timestamp)\n",
    "    end_timestamp = latest_timestamp\n",
    "  return (end_timestamp, time_interval)\n",
    "\n",
    "# Definition of a named tuple to encapsulate the parameters for a modbus request\n",
    "ModbusParameters = namedtuple(\"ModbusParameters\", [\"end_timestamp\", \"time_interval\", \"timezone\"])\n",
    "\n",
    "def modbus_request_parameters(\n",
    "    start_date_str: str = START_DATE, \n",
    "    end_date_str: str = END_DATE, \n",
    "    timezone: str = DEFAULT_TIMEZONE) -> ModbusParameters:\n",
    "  \"\"\"\n",
    "  Method to map configuration values to the named tuple with parameters for a modbus request.\n",
    "  \"\"\"\n",
    "  timestamp_end, time_interval = convert_dates_to_timestamp_and_interval(start_date_str, end_date_str)\n",
    "  return ModbusParameters(timestamp_end, time_interval, timezone)\n",
    "\n",
    "def load_modbus_data(\n",
    "    device_id: str, \n",
    "    modbus_params: dict) -> list:\n",
    "  \"\"\"\n",
    "  Method to load modbus data for a device for the specified period.\n",
    "  \"\"\"\n",
    "  print(\"load modbus data for\", device_id)\n",
    "  # If required, adjust requested time period based on first and latest available modbus data\n",
    "  adjusted_time_period = adjusted_time_period_for(device_id, modbus_params.end_timestamp, modbus_params.time_interval)\n",
    "  if adjusted_time_period is None:\n",
    "    print(f\"no modbus data available for device {device_id} for the requested period\")\n",
    "    return None\n",
    "  end_timestamp, time_interval = adjusted_time_period\n",
    "  endpoint = f\"/modbus/{device_id}\"\n",
    "  return load(endpoint, end_timestamp, time_interval)\n",
    "\n",
    "def load_modbus_data_for_devices(devices: list, modbus_params: dict) -> list:\n",
    "  \"\"\"\n",
    "  Method to load modbus data for the list of devices passed in.\n",
    "  \"\"\"\n",
    "  results = []\n",
    "\n",
    "  # Helper method to generate a dictionary with an id, data and (optionally) device metadata\n",
    "  def device_modbus_dict_for(device_id: str, timezone: str, data: dict, metadata: dict):\n",
    "    if INCLUDE_DATE_AND_TIME:\n",
    "      tz = pytz.timezone(timezone)\n",
    "      def _include_date_and_time(interval: dict) -> dict:\n",
    "        datetime = dt.datetime.fromtimestamp(interval[\"timestamp\"], tz)\n",
    "        interval[\"date\"] = datetime.strftime(\"%m/%d/%Y\")\n",
    "        interval[\"time\"] = datetime.strftime(\"%H:%M:%S\")\n",
    "        return interval\n",
    "      data = list(map(_include_date_and_time, data))\n",
    "\n",
    "    device_modbus_dict = {\n",
    "        \"id\": device_id,\n",
    "        \"data\": data\n",
    "    }\n",
    "    if metadata is not None:\n",
    "      device_modbus_dict[\"metadata\"] = metadata\n",
    "    return device_modbus_dict\n",
    "    \n",
    "  for device_id in devices:\n",
    "    device_data = get_device_status(device_id)\n",
    "    # Ignore any devices that do not support modbus\n",
    "    if device_data.get(\"model\") != \"6M+One\":\n",
    "      print(f\"device {device_data['id']} does not support modbus. (device model: {device_data.get('model', '')})\")\n",
    "      continue\n",
    "    device_timezone = device_data.get(\"timezone\") or modbus_params.timezone \n",
    "    device_le = load_modbus_data(device_id, modbus_params)\n",
    "    if device_le is None:\n",
    "      continue\n",
    "    device_modbus_dict = device_modbus_dict_for(device_id, device_timezone, device_le, device_data)\n",
    "    results.append(device_modbus_dict)\n",
    "  return results\n",
    "  \n",
    "def load_modbus_data_for_all_devices(modbus_params: dict) -> list:\n",
    "  \"\"\"\n",
    "  Method to load modbus data for all devices associated with the API key for the specified period.\n",
    "  \"\"\"\n",
    "  devices = get_devices_list()\n",
    "  if devices is None:\n",
    "    return []\n",
    "  if not devices: \n",
    "    print(\"no devices associated with the API key\")\n",
    "    return []\n",
    "  return load_modbus_data_for_devices(devices, modbus_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4xzd7Nm-h8-"
   },
   "source": [
    "# Load modbus data\n",
    "The code block below loads modbus data for all devices associated with the API key that have modbus devices attached based on the configuration values defined at the start of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nabHoTnFqZ-c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = modbus_request_parameters()\n",
    "modbus_data = load_modbus_data_for_all_devices(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjVMflQXVloh"
   },
   "source": [
    "## Saving data to Google Drive\n",
    "The block below allows you to save your data to a file on Google Drive - and download it to your local hard drive. Both JSON and CSV formats are supported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFzPcewMRQ_H"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import csv\n",
    "\n",
    "def save_data_to_json_file(data: list, file_name: str, with_indent: bool = True) -> list:\n",
    "  \"\"\"\n",
    "  Method to save data to JSON file on Google Drive\n",
    "  The data includes metadata for every device.\n",
    "  Passing in true for withIndent will indent the saved JSON for readability.\n",
    "  This will significantly increase the file size, so only do so if you aim to read the raw JSON.\n",
    "  \"\"\"\n",
    "  with open(f\"/gdrive/My Drive/{file_name}.json\", \"w\") as f:\n",
    "    indent = 4 if with_indent else None\n",
    "    json.dump(data, f, indent=indent)\n",
    "  return [f\"{file_name}.json\"] \n",
    "\n",
    "def save_data_to_csv_files(data: list, file_name: str) -> list:\n",
    "  \"\"\"\n",
    "  Method to save data to CSV files on Google Drive\n",
    "  Depending on configurations this saves:\n",
    "  - 1 file with modbus data for all devices and 1 file with metadata for all devices (allowing mapping of channels to categories, etc.)\n",
    "  - 1 data file per device, using channel category labels in the headers.\n",
    "  \"\"\"\n",
    "  if ONE_FILE_PER_DEVICE:\n",
    "    return save_modbus_data_to_csv_file_per_device(data, file_name)\n",
    "  else:\n",
    "    save_modbus_data_to_csv_file(data, file_name)\n",
    "    save_device_data_to_csv_file(data, f\"{file_name}-devices\")\n",
    "    return [f\"{file_name}.csv\", f\"{file_name}-devices.csv\"]\n",
    "\n",
    "def reorder_header_list(headers: list) -> list:\n",
    "  \"\"\"\n",
    "  Helper method to reorder the list of CSV header values.\n",
    "  \"\"\"\n",
    "  def _move_to_front(key: str):\n",
    "        if key not in headers:\n",
    "            return\n",
    "        headers.remove(key)\n",
    "        headers.insert(0, key)\n",
    "\n",
    "  _move_to_front(\"duration\")\n",
    "  if INCLUDE_DATE_AND_TIME:\n",
    "    _move_to_front(\"time\")\n",
    "    _move_to_front(\"date\")\n",
    "  _move_to_front(\"timestamp\")\n",
    "  _move_to_front(\"model\")\n",
    "  return headers\n",
    "\n",
    "def save_modbus_data_to_csv_file_per_device(data: list, file_name: str):\n",
    "  \"\"\"\"\n",
    "  Method to save modbus data for each device to a separate CSV file in Google Drive\n",
    "  Column headers will include the channel\"s category label.\n",
    "  \"\"\"\n",
    "  file_names = []\n",
    "  for device in data:\n",
    "    device_id = device[\"id\"]\n",
    "    # Ignore device if there\"s no associated modbus data\n",
    "    if len(device[\"data\"]) == 0:\n",
    "      print(f\"Ignoring device {device_id}: no associated modbus data\")\n",
    "      continue\n",
    "\n",
    "    headers = list(device[\"data\"][0].keys())\n",
    "    headers = reorder_header_list(headers)\n",
    "    # add device id to headers\n",
    "    headers.insert(0, \"device_id\")\n",
    "\n",
    "    file_name_for_device = f\"{file_name}-{device_id}.csv\"\n",
    "    with open(f\"/gdrive/My Drive/{file_name_for_device}\", \"w\", newline=\"\") as f:\n",
    "      writer = csv.DictWriter(f, headers)\n",
    "      writer.writeheader()\n",
    "      for item in device[\"data\"]:\n",
    "        item[\"device_id\"] = device_id\n",
    "        writer.writerow(item)\n",
    "    file_names.append(file_name_for_device)\n",
    "\n",
    "  return file_names   \n",
    "\n",
    "def save_modbus_data_to_csv_file(data: list, file_name: str):\n",
    "  \"\"\"\n",
    "  Method to save modbus data for all devices to a CSV file on Google Drive\n",
    "  \"\"\"\n",
    "\n",
    "  # generate headers\n",
    "  def _generate_csv_headers(data: dict) -> dict:\n",
    "    header_fields = []\n",
    "    for device in data:\n",
    "      if len(device[\"data\"]) > 0:\n",
    "        keys = device[\"data\"][0].keys()\n",
    "        for key in keys:\n",
    "          if not key in header_fields:\n",
    "            header_fields.append(key)\n",
    "       \n",
    "    if len(header_fields) == 0:\n",
    "      return None\n",
    "        \n",
    "    headers = reorder_header_list(header_fields)\n",
    "    headers.insert(0, \"device_id\")\n",
    "    return headers\n",
    "  \n",
    "  headers = _generate_csv_headers(data)\n",
    "  if headers is None:\n",
    "    print(\"None of the devices have associated modbus data. CSV export aborted.\")\n",
    "    return\n",
    "\n",
    "  with open(f\"/gdrive/My Drive/{file_name}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, headers)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for device in data:\n",
    "      device_id = device[\"id\"]\n",
    "      for item in device[\"data\"]:\n",
    "        item[\"device_id\"] = device_id\n",
    "        writer.writerow(item)\n",
    "\n",
    "def save_device_data_to_csv_file(data: list, file_name: str):\n",
    "  \"\"\"\n",
    "  Method to save metadata for all devices to a CSV file on Google Drive\n",
    "  The metadata can be used to map channel category labels for a device to its modbus data, amongst other things.\n",
    "  \"\"\"\n",
    "  \n",
    "  def _device_row_from_device_data(data: dict) -> dict:\n",
    "    metadata = data[\"metadata\"]\n",
    "    if not \"timezone\"in metadata:\n",
    "      metadata[\"timezone\"] = \"\"\n",
    "        \n",
    "    row = {\"device_id\": metadata[\"id\"], \"timezone\": metadata[\"timezone\"], \"phases_count\": metadata[\"phases\"][\"count\"], \"model\": metadata[\"model\"]}\n",
    "    for idx, channel_data in enumerate(metadata[\"channels\"]):\n",
    "      for key, value in channel_data.items():\n",
    "        row[f\"channel_{idx}_{key}\"] = value\n",
    "    return row\n",
    "\n",
    "  def _generate_csv_headers(data: Optional[list]) -> Optional[list]:\n",
    "    if data is None:\n",
    "      return None\n",
    "    header_fields = None\n",
    "    for device in data:\n",
    "      header_fields_device = list(_device_row_from_device_data(device).keys())\n",
    "      if header_fields is None or (len(header_fields_device) > len(header_fields)):\n",
    "        header_fields = header_fields_device\n",
    "    return header_fields\n",
    "\n",
    "  headers = _generate_csv_headers(data)\n",
    "  if headers is None:\n",
    "    print(\"No devices found. CSV export aborted.\")\n",
    "    return\n",
    "  \n",
    "  with open(f\"/gdrive/My Drive/{file_name}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, headers)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for device in data:\n",
    "      row = _device_row_from_device_data(device)\n",
    "      writer.writerow(row)\n",
    "\n",
    "def save_data(\n",
    "    data: list, \n",
    "    file_name: str = FILE_NAME, \n",
    "    output_format: str = OUTPUT_FORMAT, \n",
    "    download_after_save: bool = DOWNLOAD_FILE):\n",
    "  \"\"\"\n",
    "  Method to save data to file on Google Drive (either in CSV or JSON format)\n",
    "  With the option to download the file to your local hard drive.\n",
    "  \"\"\"\n",
    "  saved_files = []\n",
    "  if output_format == \"csv\":\n",
    "    saved_files = save_data_to_csv_files(data, file_name)\n",
    "  elif output_format == \"json\":\n",
    "    saved_files = save_data_to_json_file(data, file_name)\n",
    "  else:\n",
    "    print(f\"unsupported output format {output_format}. Only csv and json are supported.\")\n",
    "    return\n",
    "  if download_after_save:\n",
    "    for file in saved_files:\n",
    "      files.download(f\"/gdrive/My Drive/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59JWCzXnXQ8I"
   },
   "outputs": [],
   "source": [
    "# Save the downloaded data to file, \n",
    "# based on the values defined in the configuration code block at the start of the notebook.\n",
    "save_data(modbus_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wattwatchers_rest_api_v3_long_energy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
